# Syllabus

**Week 1: Basic Statistics**

During this first week, we show how to download and install R on Windows and the Mac. We review those basics of inferential and descriptive statistics that you'll need during the course.

Learning Objectives
- Download and install R.
- Visualize various statistics graphically.
- Create scatter plots and draw inferences from a simple linear regression model in R.

**Week 2: Visualizing Time Series, and Beginning to Model Time Series**

In this week, we begin to explore and visualize time series available as acquired data sets. We also take our first steps on developing the mathematical models needed to analyze time series data.

Learning Objectives
- Analyze time series data through software.
- Describe a time series via time plot.
- Estimate and recognize some simple Autocorrelation Functions (ACF).
- Produce random walk and form simple moving averages for datasets.

**Week 3: Stationarity, MA(q) and AR(p) processes**

In Week 3, we introduce few important notions in time series analysis: Stationarity, Backward shift operator, Invertibility, and Duality. We begin to explore Autoregressive processes and Yule-Walker equations.

Learning Objectives
- Explain stationarity in a time series.
- Simulate (construct) moving average MA(q) processes and autoregressive AR(p) processes.
- Interpret the common notation used for MA(q) processes, use invertibility condition and learn duality.
- Calculate and evaluate the ACF to distinguish between various lower order models.
- Develop Yule-Walker equations to calculate the ACF of AR(p) processes.

**Week 4: AR(p) processes, Yule-Walker equations, PACF**

In this week, partial autocorrelation is introduced. We work more on Yule-Walker equations, and apply what we have learned so far to few real-world datasets.

Learning Objectives
- Simulate and analyze autoregressive time series processes of order p, AR(p).
- Build AR(p) stochastic process models from real-world time series.
- Write Yule-Walker equations in matrix notation, and estimate model parameters in AR(p) processes.
- Examine partial autocorrelation function and use it to estimate the order of AR(p) processes.

**Week 5: Akaike Information Criterion (AIC), Mixed Models, Integrated Models**

In Week 5, we start working with Akaike Information criterion as a tool to judge our models, introduce mixed models such as ARMA, ARIMA and model few real-world datasets.

Learning Objectives
- Judge the quality of the fitted model by using Akaike Information Criterion (AIC).
- Fit a lower order ARMA or ARIMA model to a time series by assessing a reasonable (p,q) order using ACF and PACF.
- Construct ARMA models as AR infinity and MA infinity processes.
- Detrend time series data via differencing to produce a stationary process.
- Find and interpret the Ljung-Box Q-statistic in a modeling process.

**Week 6: Seasonality, SARIMA, Forecasting**

In the last week of our course, another model is introduced: SARIMA. We fit SARIMA models to various datasets and start forecasting.

Learning Objectives
- Write SARIMA models using difference and backshift operator.
- Fit SARIMA models to some time series using sarima() routine from 'astsa' package.
- Develop forecasts using exponential smoothing techniques.


# Certificate

![Certificate](https://s3.amazonaws.com/coursera_assets/meta_images/generated/CERTIFICATE_LANDING_PAGE/CERTIFICATE_LANDING_PAGE~FTRJANPY8J66/CERTIFICATE_LANDING_PAGE~FTRJANPY8J66.jpeg)